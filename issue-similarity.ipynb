{
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Experiment: issue similarity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Load packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from github import Github\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TFAutoModelForQuestionAnswering\n",
    ")\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "source": [
    "## Define global variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How to do question answering?\"\n",
    "github_org = \"huggingface\"\n",
    "github_repo = \"transformers\""
   ]
  },
  {
   "source": [
    "# Define GitHub utilities"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GitHubUtils():\n",
    "    def __init__(self, org, repo):\n",
    "        self._org = org\n",
    "        self._repo = repo\n",
    "        self._github = Github()\n",
    "        self._repo = self._github.get_repo(f\"{self._org}/{self._repo}\")\n",
    "        self._issues = self._repo.get_issues(state='closed')\n",
    "    \n",
    "    def get_issues(self):\n",
    "        return self._issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RateLimitExceededException",
     "evalue": "403 {\"message\": \"API rate limit exceeded for 71.198.193.157. (But here's the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.)\", \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"}",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitExceededException\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-20229c38b381>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGitHubUtils\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgithub_org\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgithub_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-360e0c96f195>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, org, repo)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_github\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGithub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_github\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self._org}/{self._repo}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_issues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_issues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'closed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/github/MainClass.py\u001b[0m in \u001b[0;36mget_repo\u001b[0;34m(self, full_name_or_id, lazy)\u001b[0m\n\u001b[1;32m    328\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__requester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             )\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__requester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequestJsonAndCheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mRepository\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRepository\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__requester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/github/Requester.py\u001b[0m in \u001b[0;36mrequestJsonAndCheck\u001b[0;34m(self, verb, url, parameters, headers, input)\u001b[0m\n\u001b[1;32m    353\u001b[0m         return self.__check(\n\u001b[1;32m    354\u001b[0m             *self.requestJson(\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mverb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__customConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m             )\n\u001b[1;32m    357\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/github/Requester.py\u001b[0m in \u001b[0;36m__check\u001b[0;34m(self, status, responseHeaders, output)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__structuredFromJson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__createException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponseHeaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponseHeaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRateLimitExceededException\u001b[0m: 403 {\"message\": \"API rate limit exceeded for 71.198.193.157. (But here's the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.)\", \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"}"
     ]
    }
   ],
   "source": [
    "gh = GitHubUtils(github_org, github_repo)"
   ]
  },
  {
   "source": [
    "## Load pre-trained BERT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased-distilled-squad were not used when initializing TFDistilBertForQuestionAnswering: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased-distilled-squad and are newly initialized: ['dropout_132']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"distilbert-base-uncased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = gh.get_issues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7308ccbaef7f4a7db69a550ab37880ba"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " # # environment info - transformers version : 4. 5. 1 - python version : python 3. 7 - using gpu in script? yes # # # who can help\n",
      "Question: How to do question answering?\n",
      "Answer: mention them, if possible by @ gh - username\n",
      "Question: How to do question answering?\n",
      "Answer: instantiating an automodelthe current ` _ baseautomodelclass ` class initialization does not accept any argument, and therefore fails with an arcane error when instantiating it incorrectly\n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: using my own modified scripts\n",
      "Question: How to do question answering?\n",
      "Answer: flax port vision transformer to flaxport the existing vision - transformer to flax. [SEP]\n",
      "Question: How to do question answering?\n",
      "Answer: fixes a typo or improves the docs\n",
      "Question: How to do question answering?\n",
      "Answer: yes - using distributed or parallel set - up in script\n",
      "Question: How to do question answering?\n",
      "Answer: if you can figure out the right person to tag\n",
      "Question: How to do question answering?\n",
      "Answer: don't forget to fill out the missing fields\n",
      "Question: How to do question answering?\n",
      "Answer: config entries @ sgugger\n",
      "Question: How to do question answering?\n",
      "Answer: integrates the trainer with [ neptune. ai ] ( https : / / neptune. ai / ) to start with neptune. ai logging : 1 ) set env variables\n",
      "Question: How to do question answering?\n",
      "Answer: masks are flipped\n",
      "Question: How to do question answering?\n",
      "Answer: use ` self. assertequal ` instead of ` assert ` in deberta v2 test\n",
      "Question: How to do question answering?\n",
      "Answer: using distributed or parallel set - up in script\n",
      "Question: How to do question answering?\n",
      "Answer: pr\n",
      "Question: How to do question answering?\n",
      "Answer: your pr is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: tell the user what's being processed\n",
      "Question: How to do question answering?\n",
      "Answer: modifying the distill bert architecturecurrently getting the following error while running the distillbert model : * * typeerror : forward ( ) got an unexpected keyword argument\n",
      "Question: How to do question answering?\n",
      "Answer: test optuna and rayrun the slow tests\n",
      "Question: How to do question answering?\n",
      "Answer: fixed wrong method call fixed. modified according to : https : / / pytorch. org / xla / release / 1. 8. 1 / _ modules / torch _ xla / core / xla _ model. html tpu training\n",
      "Question: How to do question answering?\n",
      "Answer: don't forget to fill out the missing fields\n",
      "Question: How to do question answering?\n",
      "Answer: fixes a typo or improves the docs\n",
      "Question: How to do question answering?\n",
      "Answer: your pr is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: using distri\n",
      "Question: How to do question answering?\n",
      "Answer: i try api call to embedding pipeline\n",
      "Question: How to do question answering?\n",
      "Answer: trying to implement pegasus distillation\n",
      "Question: How to do question answering?\n",
      "Answer: headmasking\n",
      "Question: How to do question answering?\n",
      "Answer: [CLS]\n",
      "Question: How to do question answering?\n",
      "Answer: my own modified scripts\n",
      "Question: How to do question answering?\n",
      "Answer: fixes a typo or improves the docs\n",
      "Question: How to do question answering?\n",
      "Answer: push this custom model onto model hub\n",
      "Question: How to do question answering?\n",
      "Answer: freezing\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: returns them as a tuple\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: adds a few lines of code to the trainer\n",
      "Question: How to do question answering?\n",
      "Answer: corrected\n",
      "Question: How to do question answering?\n",
      "Answer: fill out the missing fields\n",
      "Question: How to do question answering?\n",
      "Answer: check the difference and added a simple test run code\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: using distributed or parallel set - up in sc\n",
      "Question: How to do question answering?\n",
      "Answer: report the number of observed examples in the evaluation loop\n",
      "Question: How to do question answering?\n",
      "Answer: motivation relation extraction between named entities is a well - known nlp task. for example, when you get entities relative to medications\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: run the hosted inference successfully\n",
      "Question: How to do question answering?\n",
      "Answer: adds the clip model\n",
      "Question: How to do question answering?\n",
      "Answer: don't forget to fill out the missing fields\n",
      "Question: How to do question answering?\n",
      "Answer: contribute to add jax implementation for the remaining ones\n",
      "Question: How to do question answering?\n",
      "Answer: trainer : @ sgugger # # information model i am using\n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: try to add token\n",
      "Question: How to do question answering?\n",
      "Answer: if you choose to work on this small project, please comment that you're working on it\n",
      "Question: How to do question answering?\n",
      "Answer: fixes a typo or improves the docs\n",
      "Question: How to do question answering?\n",
      "Answer: when using distributed training\n",
      "Question: How to do question answering?\n",
      "Answer: bert tokenizer and bert model have there packages saved in my local. * * i am unable to understand how should i achieve it in my local without any internet connection\n",
      "Question: How to do question answering?\n",
      "Answer: using distributed or parallel set - up in script\n",
      "Question: How to do question answering?\n",
      "Answer: cpu, gpu? if using multiple gpus\n",
      "Question: How to do question answering?\n",
      "Answer: cpu, gpu? if using multiple gpus\n",
      "Question: How to do question answering?\n",
      "Answer: using the pret\n",
      "Question: How to do question answering?\n",
      "Answer: details in the attached image\n",
      "Question: How to do question answering?\n",
      "Answer: torchscript tests to the slow suite. the current ci isn't passing because it crashes and exceeds the 10 - minute timeout, this pr is a first step into fixing that. will look into re - enabling the torchscript tests on each commit\n",
      "Question: How to do question answering?\n",
      "Answer: merging now to have ci pass\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: eval\n",
      "Question: How to do question answering?\n",
      "Answer: calling the model from an nlp framework\n",
      "Question: How to do question answering?\n",
      "Answer: don't forget to fill out the missing fields\n",
      "Question: How to do question answering?\n",
      "Answer: improves the docs\n",
      "Question: How to do question answering?\n",
      "Answer: give the best performance by default\n",
      "Question: How to do question answering?\n",
      "Answer: don't forget to fill out the missing fields\n",
      "Question: How to do question answering?\n",
      "Answer: validation and 2k for the test dataset. i have used the following example for my dataset\n",
      "Question: How to do question answering?\n",
      "Answer: fixes a reference to the xlnet page in the documentation of trainingarguments\n",
      "Question: How to do question answering?\n",
      "Answer: no # # # who can help @ sgugger @ patrickvonplaten # # information\n",
      "Question: How to do question answering?\n",
      "Answer: users that wish to use a flo - logging callback can access it more frequently\n",
      "Question: How to do question answering?\n",
      "Answer: issues loading finetuned berthello, i â€™ m having issues loading a finetuned bert model for binary classification\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: trying to convert using the tuned checkpoint\n",
      "Question: How to do question answering?\n",
      "Answer: if you can figure out the right pers\n",
      "Question: How to do question answering?\n",
      "Answer: if this argument is set to a positive int\n",
      "Question: How to do question answering?\n",
      "Answer: by setting it to ` none\n",
      "Question: How to do question answering?\n",
      "Answer: using gpu in script? : yes - using distributed or parallel set - up in script\n",
      "Question: How to do question answering?\n",
      "Answer: fill out the missing fields\n",
      "Question: How to do question answering?\n",
      "Answer: copy - and - paste its output below. don't forget to fill out the missing fields\n",
      "Question: How to do question answering?\n",
      "Answer: fixes a typo or improves the docs\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: trying to train using : model _ name ='emilyalsentzer / bio _ clinicalbert'model = text\n",
      "Question: How to do question answering?\n",
      "Answer: keep _ in _ memory = false `, to disable in - memory cache\n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: log on one node\n",
      "Question: How to do question answering?\n",
      "Answer: updates the trainer to report both\n",
      "Question: How to do question answering?\n",
      "Answer: add a seperate nn. linear ( ) head on top of the already fine - tuned bertforsequenceclassification model and train the entire model\n",
      "Question: How to do question answering?\n",
      "Answer: the output of ` bert _ mode\n",
      "Question: How to do question answering?\n",
      "Answer: when i substitute another task, such as ` task ='sentiment'`, it works fine. i have also tried using the ` cardiffnlp / twitter - roberta - base - emotion ` model within an nlp framework\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: when necessary\n",
      "Question: How to do question answering?\n",
      "Answer: integration of hf\n",
      "Question: How to do question answering?\n",
      "Answer: add the features needed to use ` pretrainedtokenizerfast ` as a standalone tokenizer\n",
      "Question: How to do question answering?\n",
      "Answer: thanks\n",
      "Question: How to do question answering?\n",
      "Answer: use ddp pluggings as a replacement\n",
      "Question: How to do question answering?\n",
      "Answer: huge model to be loaded in small chunks per gpu at once\n",
      "Question: How to do question answering?\n",
      "Answer: don't forget to fill out the missing fields\n",
      "Question: How to do question answering?\n",
      "Answer: chunk the existing dataset into smaller pieces\n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: quickly whip up a model of any desired size for the big - science experiments\n",
      "Question: How to do question answering?\n",
      "Answer: tell the user what's being processed\n",
      "Question: How to do question answering?\n",
      "Answer: repeated logging\n",
      "Question: How to do question answering?\n",
      "Answer: concatenating the lists with sum ( ) may be repeatedly reallocating memory with each successive concatenation\n",
      "Question: How to do question answering?\n",
      "Answer: not to load itunrequested tf loading\n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: fixes the regression introduced in # 11012 for regression problems with only one label ( like sts - b ), see discussion on # 11780. i checked both ` run _ glue ` and ` run _ glue _ no _ trainer ` on this branch and get the proper results for this task now\n",
      "Question: How to do question answering?\n",
      "Answer: fixes that\n",
      "Question: How to do question answering?\n",
      "Answer: a description of the change\n",
      "Question: How to do question answering?\n",
      "Answer: userwarning : using a target size\n",
      "Question: How to do question answering?\n",
      "Answer: automatically upload models to the hub\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: fix usage of head masks\n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: add doi badge to readme\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: error\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: provides a much cleaner and less hacky implementation of symbolic tracing for models of the library\n",
      "Question: How to do question answering?\n",
      "Answer: who can review? anyone in the community is free to review the pr once the tests have passed\n",
      "Question: How to do question answering?\n",
      "Answer: process all the input simultaneously\n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: run the command ` transformers - cli env ` and copy - and - paste its output below\n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: fixes a typo or improves the docs\n",
      "Question: How to do question answering?\n",
      "Answer: distribution of attention modules across multiple gpus\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: adds tests\n",
      "Question: How to do question answering?\n",
      "Answer: fine - tune a dutch summarization algorithm\n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: your pr is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: solves the issue for symbolic tracing with t5\n",
      "Question: How to do question answering?\n",
      "Answer: add visual + link\n",
      "Question: How to do question answering?\n",
      "Answer: remove tapas model card\n",
      "Question: How to do question answering?\n",
      "Answer: refactoring\n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: time limit ` ci / circleci : run _ tests _ torch ` reaches 10 min. time limit\n",
      "Question: How to do question answering?\n",
      "Answer: cpu, gpu? if using multiple gpus\n",
      "Question: How to do question answering?\n",
      "Answer: ensures we actually use the ` weight _ decay ` command - line argument - simplified ` jax. value _ and _ grad ` by removing the auxiliary ( which we don't use ) - simplified replication logic\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: position _ enc will be error\n",
      "Question: How to do question answering?\n",
      "Answer: use a customer tokenizer trained from the tokenizers library in a pretrainedtokenizer interface? ` ` ` from tokenizers import tokenizer tokenizer = tokenizer. from _ file ( config _ file ) ` ` ` the config file is generated using tokenizer. save ( ) method. i want to use this tokenizer in a pretrainedtokenizer / pretrainedtokenizerfast class\n",
      "Question: How to do question answering?\n",
      "Answer: python - m torch\n",
      "Question: How to do question answering?\n",
      "Answer: single task\n",
      "Question: How to do question answering?\n",
      "Answer: it fixes the best model loading on the last stage of the training. fixes # 11666 # # who can review\n",
      "Question: How to do question answering?\n",
      "Answer: fixes a crash\n",
      "Question: How to do question answering?\n",
      "Answer: error message\n",
      "Question: How to do question answering?\n",
      "Answer: fix gpt - 2 warningscloses\n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: your pr is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: using gpu in script\n",
      "Question: How to do question answering?\n",
      "Answer: remove defaults to none if optionalpr to fix # 11687\n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: text - classification # mixed - precision - training showed a comparison between models trained with and without mixed precision\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: stores the old model in the new mo\n",
      "Question: How to do question answering?\n",
      "Answer: i can provide a pr\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: to make sure the mechanism used is not broken by mistake\n",
      "Question: How to do question answering?\n",
      "Answer: ignore _ subwords ` and ` grouped _ entities ` arguments are now fused into ` aggregation _ strategy `\n",
      "Question: How to do question answering?\n",
      "Answer: reran the code examples when i had to change the text inside them\n",
      "Question: How to do question answering?\n",
      "Answer: piping 5 texts\n",
      "Question: How to do question answering?\n",
      "Answer: fixes the tf roberta model for mixed precision training\n",
      "Question: How to do question answering?\n",
      "Answer: adds the macos tensorflow version mostly for the m1 apple laptop\n",
      "Question: How to do question answering?\n",
      "Answer: add the ` - - text _ column ` option to ` run _ summarization _ no _ trainer. py ` ( mostly copy from ` run _ summarization. py ` ) also removed a duplicated line\n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: fine - tune mbart - large - cc25\n",
      "Question: How to do question answering?\n",
      "Answer: don't forget to fill out the missing fields\n",
      "Question: How to do question answering?\n",
      "Answer: your pr is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution\n",
      "Question: How to do question answering?\n",
      "Answer: \n",
      "Question: How to do question answering?\n",
      "Answer: how to move and reuse preprocessed dataset\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RateLimitExceededException",
     "evalue": "403 {\"message\": \"API rate limit exceeded for 71.198.193.157. (But here's the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.)\", \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"}",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitExceededException\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-39ea8e0407b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0missue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0missues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0missue_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0missue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0missue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0missue_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/github/PaginatedList.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_couldGrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mnewElements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnewElements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/github/PaginatedList.py\u001b[0m in \u001b[0;36m_grow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_grow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mnewElements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetchNextPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__elements\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnewElements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnewElements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/github/PaginatedList.py\u001b[0m in \u001b[0;36m_fetchNextPage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fetchNextPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         headers, data = self.__requester.requestJsonAndCheck(\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__nextUrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__nextParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         )\n\u001b[1;32m    202\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/github/Requester.py\u001b[0m in \u001b[0;36mrequestJsonAndCheck\u001b[0;34m(self, verb, url, parameters, headers, input)\u001b[0m\n\u001b[1;32m    353\u001b[0m         return self.__check(\n\u001b[1;32m    354\u001b[0m             *self.requestJson(\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mverb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__customConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m             )\n\u001b[1;32m    357\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/github/Requester.py\u001b[0m in \u001b[0;36m__check\u001b[0;34m(self, status, responseHeaders, output)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__structuredFromJson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__createException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponseHeaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponseHeaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRateLimitExceededException\u001b[0m: 403 {\"message\": \"API rate limit exceeded for 71.198.193.157. (But here's the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.)\", \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"}"
     ]
    }
   ],
   "source": [
    "for i, issue in tqdm(enumerate(issues)):\n",
    "    if i % 100 == 0:\n",
    "        print(\"Pause 1 second to meet the GitHub API rate limit.\")\n",
    "        sleep(1)\n",
    "    issue_context = (issue.title + issue.body)[:500]\n",
    "    inputs = tokenizer(question, issue_context, add_special_tokens=True, return_tensors=\"tf\")\n",
    "    input_ids = inputs[\"input_ids\"].numpy()[0]\n",
    "    outputs = model(inputs)\n",
    "    answer_start_scores = outputs.start_logits\n",
    "    answer_end_scores = outputs.end_logits\n",
    "    answer_start = tf.argmax(answer_start_scores, axis=1).numpy()[0]\n",
    "    answer_end = (tf.argmax(answer_end_scores, axis=1) + 1).numpy()[0]\n",
    "    answer = tokenizer.convert_tokens_to_string(\n",
    "        tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}